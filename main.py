import logging
import os
import openai
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.utils import executor
from aiogram.dispatcher.filters import CommandStart
from aiogram.dispatcher import FSMContext
from aiogram.contrib.fsm_storage.memory import MemoryStorage
from aiogram.dispatcher.filters.state import State, StatesGroup

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
logging.basicConfig(level=logging.INFO)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not BOT_TOKEN:
    raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω–∞")
if not OPENAI_API_KEY:
    raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞")

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(bot, storage=MemoryStorage())
openai.api_key = OPENAI_API_KEY

# –ú–∞—à–∏–Ω–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π
class StoryState(StatesGroup):
    waiting_for_name = State()
    waiting_for_theme = State()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ /start
@dp.message_handler(CommandStart())
async def start(message: Message, state: FSMContext):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –ë—É–ª—å—Ç—ã—Ö–≤–æ—Å—Ç-—Å–∫–∞–∑–æ—á–Ω–∏–∫ üêæ\n–ö–∞–∫ –∑–æ–≤—É—Ç —Ä–µ–±—ë–Ω–∫–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–æ—á–∏–Ω—è—Ç—å —Å–∫–∞–∑–∫–∏?")
    await state.set_state(StoryState.waiting_for_name.state)

# –ò–º—è —Ä–µ–±—ë–Ω–∫–∞
@dp.message_handler(state=StoryState.waiting_for_name)
async def get_name(message: Message, state: FSMContext):
    await state.update_data(child_name=message.text)
    await message.answer(f"–ò–º—è —Ä–µ–±—ë–Ω–∫–∞ ‚Äî {message.text}? –û—Ç–ª–∏—á–Ω–æ! –¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–∏ —Ç–µ–º—É —Å–∫–∞–∑–∫–∏ üåü")
    await state.set_state(StoryState.waiting_for_theme.state)

# –¢–µ–º–∞ —Å–∫–∞–∑–∫–∏
@dp.message_handler(state=StoryState.waiting_for_theme)
async def get_theme(message: Message, state: FSMContext):
    await state.update_data(theme=message.text)
    await message.answer("–ü–∏—à—É —Å–∫–∞–∑–∫—É... üìñ")

    data = await state.get_data()
    child_name = data["child_name"]
    theme = data["theme"]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{
                "role": "user",
                "content": f"–°–æ—á–∏–Ω–∏ –¥–æ–±—Ä—É—é —Å–∫–∞–∑–∫—É –¥–ª—è —Ä–µ–±—ë–Ω–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {child_name} –Ω–∞ —Ç–µ–º—É: {theme}"
            }],
            max_tokens=600,
            temperature=0.9,
        )
        story = response["choices"][0]["message"]["content"]
        await message.answer(story)
    except Exception as e:
        await message.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—á–∏–Ω–∏—Ç—å —Å–∫–∞–∑–∫—É üò¢\n–û—à–∏–±–∫–∞: {e}")

    await state.finish()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª—é–±–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ /start
@dp.message_handler()
async def fallback(message: Message):
    await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏ —Å–Ω–∞—á–∞–ª–∞ —Å –∫–æ–º–∞–Ω–¥—ã /start.")

if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)


