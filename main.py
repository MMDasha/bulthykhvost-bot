import os
from aiogram import Bot, Dispatcher, types
from aiogram.types import ParseMode
from aiogram.utils import executor
from dotenv import load_dotenv
import openai

# –ó–∞–≥—Ä—É–∑–∫–∞ .env
load_dotenv()

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_API_TOKEN = os.getenv("TELEGRAM_API_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–æ–∫–µ–Ω–æ–≤
if not TELEGRAM_API_TOKEN:
    raise ValueError("TELEGRAM_API_TOKEN is not set")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY is not set")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
bot = Bot(token=TELEGRAM_API_TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher(bot)
openai.api_key = OPENAI_API_KEY

# –ü—Ä–æ—Å—Ç–∞—è FSM –Ω–∞ —Å–ª–æ–≤–∞—Ä–µ
user_state = {}

@dp.message_handler(commands=["start"])
async def cmd_start(message: types.Message):
    user_state[message.from_user.id] = {"step": "get_name"}
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –ë—É–ª—å—Ç—ã—Ö–≤–æ—Å—Ç-—Å–∫–∞–∑–æ—á–Ω–∏–∫ üêæ\n–ö–∞–∫ –∑–æ–≤—É—Ç —Ä–µ–±—ë–Ω–∫–∞, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–æ—á–∏–Ω—è—Ç—å —Å–∫–∞–∑–∫–∏?")

@dp.message_handler()
async def handle_message(message: types.Message):
    user_id = message.from_user.id
    if user_id not in user_state:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏ —Å–Ω–∞—á–∞–ª–∞ —Å –∫–æ–º–∞–Ω–¥—ã /start.")
        return

    state = user_state[user_id]

    if state["step"] == "get_name":
        child_name = message.text.strip()
        state["name"] = child_name
        state["step"] = "get_topic"
        await message.answer(f"–ò–º—è —Ä–µ–±—ë–Ω–∫–∞ ‚Äî {child_name}? –û—Ç–ª–∏—á–Ω–æ! –¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–∏ —Ç–µ–º—É —Å–∫–∞–∑–∫–∏ ‚ú®")
    elif state["step"] == "get_topic":
        topic = message.text.strip()
        name = state.get("name", "–†–µ–±—ë–Ω–æ–∫")
        await message.answer("–ü–∏—à—É —Å–∫–∞–∑–∫—É... üìñ")

        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "–¢—ã –¥–æ–±—Ä—ã–π —Å–∫–∞–∑–æ—á–Ω–∏–∫, —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—é—â–∏–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ, –¥–æ–±—Ä—ã–µ, –≤–æ–ª—à–µ–±–Ω—ã–µ —Å–∫–∞–∑–∫–∏."},
                    {"role": "user", "content": f"–°–æ—á–∏–Ω–∏ –∫–æ—Ä–æ—Ç–∫—É—é —Å–∫–∞–∑–∫—É –¥–ª—è —Ä–µ–±—ë–Ω–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {name} –Ω–∞ —Ç–µ–º—É: {topic}."}
                ],
                max_tokens=500,
                temperature=0.9
            )
            story = response.choices[0].message["content"]
            await message.answer(story)
        except Exception as e:
            await message.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—á–∏–Ω–∏—Ç—å —Å–∫–∞–∑–∫—É üò¢ –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –ø–æ–∑–∂–µ.")
            print(f"OpenAI Error: {e}")

        user_state.pop(user_id)
    else:
        await message.answer("–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π /start –∑–∞–Ω–æ–≤–æ.")

if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)
