# main.py
import os
import logging
from typing import Dict

from aiogram import Bot, Dispatcher, executor, types
from aiogram.contrib.middlewares.logging import LoggingMiddleware
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

TELEGRAM_API_TOKEN = os.getenv("TELEGRAM_API_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤ .env

if not TELEGRAM_API_TOKEN:
    raise EnvironmentError("TELEGRAM_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
if not OPENAI_API_KEY:
    raise EnvironmentError("OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s"
)
log = logging.getLogger("bulthykhvost")

bot = Bot(token=TELEGRAM_API_TOKEN, parse_mode=types.ParseMode.HTML)
dp = Dispatcher(bot)
dp.middleware.setup(LoggingMiddleware())

client = OpenAI(api_key=OPENAI_API_KEY)

# –ø—Ä–æ—Å—Ç–µ–π—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤
state: Dict[int, Dict[str, str]] = {}

WELCOME = (
    "–ü—Ä–∏–≤–µ—Ç! –Ø –ë—É–ª—å—Ç—ã—Ö–≤–æ—Å—Ç-—Å–∫–∞–∑–æ—á–Ω–∏–∫ üêæ\n"
    "–ö–∞–∫ –∑–æ–≤—É—Ç —Ä–µ–±—ë–Ω–∫–∞?"
)
ASK_TOPIC = "–ò–º—è —Ä–µ–±—ë–Ω–∫–∞ ‚Äî <b>{name}</b>? –û—Ç–ª–∏—á–Ω–æ! ‚ú® –¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–∏ —Ç–µ–º—É —Å–∫–∞–∑–∫–∏."
TYPING_MSG = "–ü–∏—à—É —Å–∫–∞–∑–∫—É... üìñ"
FAILED_MSG = "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—á–∏–Ω–∏—Ç—å —Å–∫–∞–∑–∫—É. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —á—É—Ç—å –ø–æ–∑–∂–µ."

def build_prompt(child_name: str, topic: str) -> str:
    return (
        "–¢—ã –¥–æ–±—Ä—ã–π —Å–∫–∞–∑–æ—á–Ω–∏–∫. –°–æ—á–∏–Ω–∏ —Ç—ë–ø–ª—É—é, –¥–æ–±—Ä—É—é –¥–µ—Ç—Å–∫—É—é —Å–∫–∞–∑–∫—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n"
        f"–ò–º—è —Ä–µ–±—ë–Ω–∫–∞: {child_name}\n"
        f"–¢–µ–º–∞: {topic}\n\n"
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n"
        "‚Ä¢ 8‚Äì12 –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞–±–∑–∞—Ü–µ–≤\n"
        "‚Ä¢ –ü—Ä–æ—Å—Ç—ã–µ –æ–±—Ä–∞–∑—ã, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ç–æ–Ω\n"
        "‚Ä¢ –¢—ë–ø–ª–∞—è –º–æ—Ä–∞–ª—å –≤ –∫–æ–Ω—Ü–µ\n"
        "‚Ä¢ –ë–µ–∑ –Ω–∞—Å–∏–ª–∏—è –∏ –ø—É–≥–∞—é—â–∏—Ö —Å—Ü–µ–Ω\n"
    )

async def generate_story(child_name: str, topic: str) -> str:
    prompt = build_prompt(child_name, topic)

    # 1-–π –∑–∞—Ö–æ–¥ —Å –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª—å—é
    try:
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "You are a kind storyteller."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.8,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e1:
        log.exception("OpenAI error (model=%s): %s", OPENAI_MODEL, e1)

        # 2-–π –∑–∞—Ö–æ–¥ —Å –∑–∞–ø–∞—Å–Ω–æ–π –º–æ–¥–µ–ª—å—é
        fallback = "gpt-4o-mini"
        if OPENAI_MODEL != fallback:
            try:
                log.info("Retry with fallback model: %s", fallback)
                resp = client.chat.completions.create(
                    model=fallback,
                    messages=[
                        {"role": "system", "content": "You are a kind storyteller."},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.8,
                )
                return resp.choices[0].message.content.strip()
            except Exception as e2:
                log.exception("OpenAI fallback error: %s", e2)

        raise  # –ø—É—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–≤–µ—Ä—Ö—É –ø–æ–∫–∞–∂–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é FAILED_MSG

@dp.message_handler(commands=["start"])
async def cmd_start(msg: types.Message):
    state[msg.from_user.id] = {"stage": "ask_name"}
    await msg.answer(WELCOME)

@dp.message_handler(commands=["ping"])
async def cmd_ping(msg: types.Message):
    # –ë—ã—Å—Ç—Ä—ã–π —Å–∞–º–æ—Ç–µ—Å—Ç: –≤–∏–¥–∏–º –∫–ª—é—á –∏ –º–æ–¥–µ–ª—å –≤ –ª–æ–≥–∞—Ö, –Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ‚Äì –æ–∫
    log.info("PING: model=%s key_prefix=%s", OPENAI_MODEL, (OPENAI_API_KEY or "")[:10])
    await msg.answer("–Ø –Ω–∞ –º–µ—Å—Ç–µ ‚úÖ")

@dp.message_handler()
async def dialog(msg: types.Message):
    uid = msg.from_user.id
    s = state.get(uid, {"stage": "ask_name"})

    # 1) —Å–ø—Ä–∞—à–∏–≤–∞–µ–º –∏–º—è
    if s["stage"] == "ask_name":
        child_name = msg.text.strip()
        if len(child_name) > 40:
            child_name = child_name[:40]
        s["name"] = child_name
        s["stage"] = "ask_topic"
        state[uid] = s
        await msg.answer(ASK_TOPIC.format(name=child_name))
        return

    # 2) —Å–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–µ–º—É –∏ –≥–µ–Ω–µ—Ä–∏–º
    if s["stage"] == "ask_topic":
        topic = msg.text.strip()
        await msg.answer(TYPING_MSG)

        try:
            story = await generate_story(s["name"], topic)
            await msg.answer(story)
            s["stage"] = "idle"
            state[uid] = s
        except Exception as e:
            # –í –ª–æ–≥–∏ ‚Äì –ø–æ–ª–Ω–∞—è –æ—à–∏–±–∫–∞. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ‚Äì –º—è–≥–∫–æ.
            log.exception("Failed to generate story: %s", e)
            # –ï—Å–ª–∏ –∫–ª—é—á –ø—Ä–æ–µ–∫—Ç–Ω—ã–π ‚Äì –¥–∞–¥–∏–º —è–≤–Ω—É—é –ø–æ–¥—Å–∫–∞–∑–∫—É –≤ –ª–æ–≥–∞—Ö
            if (OPENAI_API_KEY or "").startswith("sk-proj-"):
                log.error("–£ –≤–∞—Å –ø—Ä–æ–µ–∫—Ç–Ω—ã–π –∫–ª—é—á (sk-proj-). –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª–∏/–ø—Ä–æ–µ–∫—Ç—É, "
                          "–ø–æ–ª—É—á–∏—Ç–µ –æ–±—ã—á–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–ª—é—á sk-‚Ä¶ –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–æ–µ–∫—Ç.")
            await msg.answer(FAILED_MSG)
        return

    # –ù–∞ "idle" –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º
    await msg.answer("–ù–∞—á–Ω—ë–º –Ω–æ–≤—É—é –∏—Å—Ç–æ—Ä–∏—é! –ù–∞–ø–∏—à–∏ /start")

if __name__ == "__main__":
    log.info("Starting bot‚Ä¶ model=%s key_prefix=%s", OPENAI_MODEL, (OPENAI_API_KEY or "")[:10])
    executor.start_polling(dp, skip_updates=True)
