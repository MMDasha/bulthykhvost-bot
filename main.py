# main.py
import os
import io
import base64
import logging
import tempfile
import subprocess

from dotenv import load_dotenv

from aiogram import Bot, Dispatcher, types
from aiogram.dispatcher.filters import Command
from aiogram.utils import executor

from openai import OpenAI

# ----------------------
# –õ–û–ì–ò
# ----------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")
log = logging.getLogger("bulthykhvost")
log.info("=== BULTHYKHOVOST BOT START v3 (aiogram v2) ===")

# ----------------------
# ENV
# ----------------------
load_dotenv(override=False)

BOT_TOKEN = os.getenv("TELEGRAM_API_TOKEN") or os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")       # –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
OPENAI_IMAGE_MODEL = os.getenv("OPENAI_IMAGE_MODEL", "gpt-image-1")

log.info("ENV has TELEGRAM_API_TOKEN? %s", "TELEGRAM_API_TOKEN" in os.environ)
log.info("ENV has OPENAI_API_KEY? %s", "OPENAI_API_KEY" in os.environ)
log.info("BOT_TOKEN detected: %s", bool(BOT_TOKEN))
log.info("OPENAI_API_KEY detected: %s", bool(OPENAI_API_KEY))

if not BOT_TOKEN:
    raise EnvironmentError("TELEGRAM_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
if not OPENAI_API_KEY:
    raise EnvironmentError("OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# ----------------------
# Telegram / OpenAI
# ----------------------
bot = Bot(token=BOT_TOKEN, parse_mode=types.ParseMode.HTML)
dp = Dispatcher(bot)
client = OpenAI(api_key=OPENAI_API_KEY)

# –ü—Ä–æ—Å—Ç–∞—è –ø–∞–º—è—Ç—å –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
STATE = {}  # chat_id: {"stage": "ask_name"/"ask_topic", "name": "–ï–≥–æ—Ä"}


# ----------------------
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ
# ----------------------
def safe_len(text: str, max_len: int = 3500) -> str:
    text = (text or "").strip()
    return text if len(text) <= max_len else text[:max_len] + "‚Ä¶"

def have_ffmpeg() -> bool:
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except Exception:
        return False

def tts_to_file(text: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (OGG-voice –µ—Å–ª–∏ –µ—Å—Ç—å ffmpeg, –∏–Ω–∞—á–µ MP3),
    –ª–∏–±–æ –±—Ä–æ—Å–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –¥–∞–∂–µ gTTS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.
    """
    # gTTS –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å –≤ requirements ‚Äî –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ª–µ–Ω–∏–≤–æ
    try:
        from gtts import gTTS
    except Exception as e:
        raise RuntimeError("gTTS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω") from e

    text = safe_len(text, 3000)
    tmp_dir = tempfile.mkdtemp(prefix="tts_")
    mp3_path = os.path.join(tmp_dir, "voice.mp3")
    ogg_path = os.path.join(tmp_dir, "voice.ogg")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è MP3
    gTTS(text=text, lang="ru").save(mp3_path)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OGG/OPUS –¥–ª—è send_voice (–µ—Å–ª–∏ –µ—Å—Ç—å ffmpeg)
    if have_ffmpeg():
        try:
            subprocess.check_call([
                "ffmpeg", "-y", "-i", mp3_path,
                "-acodec", "libopus", "-b:a", "64k",
                "-vn", ogg_path
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            return ogg_path
        except Exception:
            # –µ—Å–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è ‚Äî –≤–µ—Ä–Ω—ë–º mp3
            return mp3_path
    else:
        return mp3_path


async def send_voice_or_audio(chat_id: int, path: str, caption: str = None):
    """
    –ï—Å–ª–∏ —Ñ–∞–π–ª .ogg ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ voice, –∏–Ω–∞—á–µ –∫–∞–∫ audio.
    """
    try:
        if path.lower().endswith(".ogg"):
            with open(path, "rb") as f:
                await bot.send_voice(chat_id, voice=f, caption=caption)
        else:
            with open(path, "rb") as f:
                await bot.send_audio(chat_id, audio=f, caption=caption or "–û–∑–≤—É—á–∫–∞")
    except Exception as e:
        log.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å/–∞—É–¥–∏–æ: %s", e)


def build_story_prompt(child_name: str, topic: str) -> list:
    return [
        {"role": "system",
         "content": (
             "–¢—ã ‚Äî –¥–æ–±—Ä—ã–π —Å–∫–∞–∑–æ—á–Ω–∏–∫ –ë—É–ª—å—Ç—ã—Ö–≤–æ—Å—Ç. –ü–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–µ (8‚Äì12 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) "
             "–¥–æ–±—Ä—ã–µ —Å–∫–∞–∑–∫–∏ –¥–ª—è –¥–µ—Ç–µ–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
             "–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç—ã–µ —Ñ—Ä–∞–∑—ã, –Ω–µ–º–Ω–æ–≥–æ –º–∞–≥–∏–∏, —Ç—ë–ø–ª—ã–π —Ç–æ–Ω –∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å—á–∞—Å—Ç–ª–∏–≤—ã–π —Ñ–∏–Ω–∞–ª."
         )},
        {"role": "user",
         "content": f"–°–æ—á–∏–Ω–∏ —Å–∫–∞–∑–∫—É –¥–ª—è —Ä–µ–±—ë–Ω–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {child_name}. –¢–µ–º–∞: {topic}."}
    ]


def build_image_prompt(child_name: str, topic: str) -> str:
    return (
        f"–ù–∞—Ä–∏—Å—É–π –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é –≤ –¥–µ—Ç—Å–∫–æ–º –∫–Ω–∏–∂–Ω–æ–º —Å—Ç–∏–ª–µ –ø–æ —Å–∫–∞–∑–∫–µ –Ω–∞ —Ç–µ–º—É ¬´{topic}¬ª "
        f"–¥–ª—è —Ä–µ–±—ë–Ω–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {child_name}. –Ø—Ä–∫–∏–µ, –¥–æ–±—Ä—ã–µ —Ü–≤–µ—Ç–∞, –º—è–≥–∫–∏–µ —Ñ–æ—Ä–º—ã, "
        f"–∞–∫—Ü–µ–Ω—Ç –Ω–∞ –≥–ª–∞–≤–Ω–æ–≥–æ –≥–µ—Ä–æ—è. –ë–µ–∑ —Ç–µ–∫—Å—Ç–∞."
    )


# ----------------------
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∫–∞–∑–∫–∏
# ----------------------
def generate_story(child_name: str, topic: str) -> str:
    completion = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=build_story_prompt(child_name, topic),
        temperature=0.9,
        max_tokens=600
    )
    return (completion.choices[0].message.content or "").strip()


# ----------------------
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# ----------------------
def generate_image_b64(child_name: str, topic: str) -> bytes:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç PNG-–±–∞–π—Ç—ã –∏–ª–∏ –±—Ä–æ—Å–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç gpt-image-1.
    """
    result = client.images.generate(
        model=OPENAI_IMAGE_MODEL,
        prompt=build_image_prompt(child_name, topic),
        size="1024x1024"
    )
    b64 = result.data[0].b64_json
    return base64.b64decode(b64)


# ----------------------
# Handlers
# ----------------------
@dp.message_handler(Command("start"))
async def on_start(message: types.Message):
    chat_id = message.chat.id
    STATE[chat_id] = {"stage": "ask_name"}
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø <b>–ë—É–ª—å—Ç—ã—Ö–≤–æ—Å—Ç</b> üêæ\n"
        "–î–∞–≤–∞–π —Å–æ—á–∏–Ω–∏–º —Å–∫–∞–∑–∫—É. –ö–∞–∫ –∑–æ–≤—É—Ç —Ä–µ–±—ë–Ω–∫–∞?"
    )


@dp.message_handler(content_types=types.ContentTypes.TEXT)
async def on_text(message: types.Message):
    chat_id = message.chat.id
    text = (message.text or "").strip()

    # –Ω–∞—á–Ω—ë–º —Å—Ü–µ–Ω–∞—Ä–∏–π, –µ—Å–ª–∏ –Ω–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if chat_id not in STATE:
        STATE[chat_id] = {"stage": "ask_name"}
        await message.answer("–ö–∞–∫ –∑–æ–≤—É—Ç —Ä–µ–±—ë–Ω–∫–∞?")
        return

    stage = STATE[chat_id].get("stage")

    if stage == "ask_name":
        # —Å–æ—Ö—Ä–∞–Ω–∏–º –∏–º—è –∏ –ø–æ–ø—Ä–æ—Å–∏–º —Ç–µ–º—É
        STATE[chat_id]["name"] = safe_len(text, 64)
        STATE[chat_id]["stage"] = "ask_topic"
        await message.answer(f"–ò–º—è —Ä–µ–±—ë–Ω–∫–∞ ‚Äî <b>{STATE[chat_id]['name']}</b>. –û—Ç–ª–∏—á–Ω–æ! –¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–∏ —Ç–µ–º—É —Å–∫–∞–∑–∫–∏ ‚ú®")
        return

    if stage == "ask_topic":
        name = STATE[chat_id].get("name") or "–ú–∞–ª—ã—à"
        topic = safe_len(text, 200)
        await message.answer("–ü–∏—à—É —Å–∫–∞–∑–∫—É‚Ä¶ üìñ")

        # –ì–µ–Ω–µ—Ä–∏–º —Å–∫–∞–∑–∫—É
        try:
            story = generate_story(name, topic)
            if not story:
                raise RuntimeError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏")

            # –æ—Ç–ø—Ä–∞–≤–∏–º —Ç–µ–∫—Å—Ç
            await message.answer(story)

            # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ç—å –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é (–Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ)
            try:
                png_bytes = generate_image_b64(name, topic)
                await bot.send_photo(chat_id, photo=io.BytesIO(png_bytes), caption="–ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è üì∑")
            except Exception as e_img:
                log.warning("–ò–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è –Ω–µ —Å–æ–∑–¥–∞–Ω–∞: %s", e_img)

            # –ü–æ–ø—Ä–æ–±—É–µ–º –æ–∑–≤—É—á–∏—Ç—å (–Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ)
            try:
                voice_path = tts_to_file(story)
                await send_voice_or_audio(chat_id, voice_path, caption="–û–∑–≤—É—á–∫–∞ —Å–∫–∞–∑–∫–∏ üéôÔ∏è")
            except Exception as e_tts:
                log.warning("–û–∑–≤—É—á–∫–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞: %s", e_tts)

        except Exception as e:
            log.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∫–∞–∑–∫–∏: %s", e)
            await message.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—á–∏–Ω–∏—Ç—å —Å–∫–∞–∑–∫—É. –ü—Ä–∏—á–∏–Ω–∞: {e}")

        # —Å–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è ‚Äî –º–æ–∂–Ω–æ —Å–Ω–æ–≤–∞ –Ω–∞—á–∞—Ç—å —Å —Ç–µ–º—ã (–∏–º—è —Å–æ—Ö—Ä–∞–Ω–∏–º)
        STATE[chat_id]["stage"] = "ask_topic"
        await message.answer("–•–æ—á–µ—à—å –µ—â—ë —Ç–µ–º—É? –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –µ—ë üôÇ")
        return

    # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    STATE[chat_id] = {"stage": "ask_name"}
    await message.answer("–î–∞–≤–∞–π –Ω–∞—á–Ω—ë–º —Å–Ω–∞—á–∞–ª–∞. –ö–∞–∫ –∑–æ–≤—É—Ç —Ä–µ–±—ë–Ω–∫–∞?")


# ----------------------
# main
# ----------------------
def main():
    log.info("Starting polling (aiogram v2)‚Ä¶")
    executor.start_polling(dp, skip_updates=True)


if __name__ == "__main__":
    main()
